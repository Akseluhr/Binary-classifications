{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1\n",
    "\n",
    "Objective: to compare how models with different hyperparameter settings perform versus the baseline model on training and test data. \n",
    "\n",
    "The sample error is intentional.\n",
    "\n",
    "The dataset used for this task can be found here:\n",
    "\n",
    "https://www.kaggle.com/ronitf/heart-disease-uci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv\n",
    "df = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "5   57    1   0       140   192    0        1      148      0      0.4      1   \n",
       "6   56    0   1       140   294    0        0      153      0      1.3      1   \n",
       "7   44    1   1       120   263    0        1      173      0      0.0      2   \n",
       "8   52    1   2       172   199    1        1      162      0      0.5      2   \n",
       "9   57    1   2       150   168    0        1      174      0      1.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  \n",
       "5   0     1       1  \n",
       "6   0     2       1  \n",
       "7   0     3       1  \n",
       "8   0     3       1  \n",
       "9   0     2       1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking out the DF\n",
    "df.info()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    165\n",
      "0    138\n",
      "Name: target, dtype: int64\n",
      "Number of NaNs:  age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking the class (in)balance and NaN's\n",
    "\n",
    "print(df[\"target\"].value_counts())\n",
    "print(\"Number of NaNs: \", df.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the class labels and drop class column\n",
    "y_res = df[\"target\"]\n",
    "df.drop(['target'], 1, inplace=True)\n",
    "\n",
    "# Splitting the dataset into 50/50\n",
    "# Stratified split for equal class proportions in each dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y_res, stratify=y_res,test_size=0.5, random_state=1)\n",
    "\n",
    "# Note to myself:\n",
    "# X_train = Training data of first half\n",
    "# X_test = Second half, evaluate on this data. Don't touch\n",
    "# y_train = Class labels for X_train\n",
    "# y_test = Class labels for X_test. Don't touch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hundred_settings_ten_folds(X, y):\n",
    "    \n",
    "    #Copying X_train and y_train\n",
    "    X_train = X.copy();\n",
    "    y_train = y.copy();\n",
    "    \n",
    "    # Stratified for keeping class proportions in each fold\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "    # scaler = MinMaxScaler()\n",
    "\n",
    "    # Using Knn as learning algo\n",
    "    clf = KNeighborsClassifier()\n",
    "    \n",
    "    # kNN.get_params().keys()\n",
    "    # pipe = Pipeline(steps=[(\"scaler\", scaler), (\"kNN\", clf)])\n",
    "\n",
    "    # approx. 100 different parameter settings\n",
    "    grid_param = {\n",
    "         'n_neighbors': [1, 3, 5, 7, 10, 15, 20, 25],\n",
    "         'weights': ['uniform', 'distance'],\n",
    "         'algorithm': ['auto', 'ball_tree', \"kd_tree\", \"brute\"],\n",
    "         'leaf_size': [10, 30]\n",
    "    }\n",
    "    \n",
    "    # Grid search with 100 settings and 10 stratified splits\n",
    "    grid_sr = GridSearchCV(param_grid=grid_param,\n",
    "                           scoring='accuracy',\n",
    "                           estimator=clf,\n",
    "                           cv=skf,\n",
    "                           n_jobs=-1)\n",
    "    \n",
    "    # Fit the model according to best params\n",
    "    grid_sr.fit(X_train, y_train)\n",
    "    \n",
    "    # Display best params\n",
    "    best_parameters = grid_sr.best_params_\n",
    "    print(\"Best params: \", best_parameters)  \n",
    "    \n",
    "    # Display individual mean accuracy for each fold\n",
    "    fold_scores = grid_sr.cv_results_['mean_test_score']\n",
    "    print(\"Fold scores: \", fold_scores)\n",
    "    \n",
    "    # Display best cv result (accuracy)\n",
    "    best_result = grid_sr.best_score_\n",
    "    print(\"Best cv acc: \", best_result)\n",
    "    \n",
    "    return fold_scores;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 7, 'weights': 'distance'}\n",
      "Fold scores:  [0.60958333 0.60958333 0.64208333 0.62875    0.64166667 0.655\n",
      " 0.64791667 0.66125    0.64833333 0.64166667 0.62875    0.62833333\n",
      " 0.62166667 0.64833333 0.63541667 0.63541667 0.60958333 0.60958333\n",
      " 0.64208333 0.62875    0.64166667 0.655      0.64791667 0.66125\n",
      " 0.64833333 0.64166667 0.62875    0.62833333 0.62166667 0.64833333\n",
      " 0.63541667 0.63541667 0.60958333 0.60958333 0.64208333 0.62875\n",
      " 0.64166667 0.655      0.64791667 0.66125    0.64833333 0.64166667\n",
      " 0.62875    0.62833333 0.62166667 0.64833333 0.63541667 0.63541667\n",
      " 0.60958333 0.60958333 0.64208333 0.62875    0.64166667 0.655\n",
      " 0.64791667 0.66125    0.64833333 0.64166667 0.62875    0.62833333\n",
      " 0.62166667 0.64833333 0.63541667 0.63541667 0.60958333 0.60958333\n",
      " 0.64208333 0.62875    0.64166667 0.655      0.64791667 0.66125\n",
      " 0.64833333 0.64166667 0.62875    0.62833333 0.62166667 0.64833333\n",
      " 0.63541667 0.63541667 0.60958333 0.60958333 0.64208333 0.62875\n",
      " 0.64166667 0.655      0.64791667 0.66125    0.64833333 0.64166667\n",
      " 0.62875    0.62833333 0.62166667 0.64833333 0.63541667 0.63541667\n",
      " 0.60958333 0.60958333 0.64208333 0.62875    0.635      0.64833333\n",
      " 0.64791667 0.66125    0.64833333 0.64166667 0.62875    0.62833333\n",
      " 0.62166667 0.64833333 0.63541667 0.63541667 0.60958333 0.60958333\n",
      " 0.64208333 0.62875    0.635      0.64833333 0.64791667 0.66125\n",
      " 0.64833333 0.64166667 0.62875    0.62833333 0.62166667 0.64833333\n",
      " 0.63541667 0.63541667]\n",
      "Best cv acc:  0.6612499999999999\n"
     ]
    }
   ],
   "source": [
    "hyper_p_accuracies = hundred_settings_ten_folds(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(X, y):\n",
    "    \n",
    "    #Copying X_train and y_train\n",
    "    X_train = X.copy();\n",
    "    y_train = y.copy();\n",
    "    \n",
    "    # SK-fold 10 times\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    \n",
    "    # Using kNN\n",
    "    clf = KNeighborsClassifier()\n",
    "    \n",
    "    # Get accuracies\n",
    "    accuracy = cross_val_score(clf, X_train, y_train, scoring=\"balanced_accuracy\", cv=cv)\n",
    "    print(accuracy)\n",
    "    print(\"Avarage accuracy: \", mean(accuracy))\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42063492 0.41666667 0.53571429 0.67857143 0.58928571 0.74107143\n",
      " 0.86607143 0.33035714 0.74107143 0.58928571]\n",
      "Avarage accuracy:  0.5908730158730159\n"
     ]
    }
   ],
   "source": [
    "# Printing baseline accuracies\n",
    "baseline_accuracies = baseline(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tuned models that scored higher than the mean of baseline models:  96\n",
      "Tuned models outperformed the baseline in the majority of the cases.\n"
     ]
    }
   ],
   "source": [
    "# Checking how many times the HP model outperformed the mean accuracy of the baseline model \n",
    "\n",
    "count = 0\n",
    "for ac in hyper_p_accuracies:\n",
    "    if(ac > mean(baseline_accuracies)):\n",
    "        count = count + 1\n",
    "\n",
    "print(\"Number of tuned models that scored higher than the mean of baseline models: \", count)\n",
    "if(len(hyper_p_accuracies) > 50):\n",
    "    print(\"Tuned models outperformed the baseline in the majority of the cases.\")\n",
    "else:\n",
    "    print(\"Tuned models did not outperform the baseline in the majority of the cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to 96 tuned models outperforming the baseline model, \n",
    "# the tuned model should outperform the baseline model on the test set.\n",
    "\n",
    "# Running kNN on test data\n",
    "# With best params\n",
    "def test_with_params(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf = KNeighborsClassifier(algorithm='auto', n_neighbors=7, weights='distance')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Hyper parameter model accuracy: \", accuracy)\n",
    "\n",
    "# Running kNN on test data\n",
    "# With no params \n",
    "def test_baseline(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Baseline model accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper parameter model accuracy:  0.6842105263157895\n",
      "Baseline model accuracy:  0.6644736842105263\n"
     ]
    }
   ],
   "source": [
    "# Checking difference in accuracies between the two models\n",
    "test_with_params(X_train, X_test, y_train, y_test)\n",
    "test_baseline(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my run, the HP models outperformed the baseline models in 96 / 100 cases. Due to this, the results on the final comparison was expected.  \n",
    "\n",
    "#Final comment: \n",
    "\n",
    "Low accuracy may be a result of the small dataset and the case could also be that kNN is not performing well on this dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2\n",
    "\n",
    "Objective: to compare how class imbalance affects the accuracy, AUC and precision.\n",
    "\n",
    "In this task, I selected a dataset with approx. 20k instances, and scaled it down to approx. 4k instances of class 0 and 1k instances of class 1. This was done by randomly picking 5k samples from the original dataset during the split.\n",
    "\n",
    "The dataset can be found here:\n",
    "\n",
    "https://www.kaggle.com/volodymyrgavrysh/fraud-detection-bank-dataset-20k-records-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20468 entries, 0 to 20467\n",
      "Columns: 114 entries, Unnamed: 0 to targets\n",
      "dtypes: float64(1), int64(113)\n",
      "memory usage: 17.8 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    3757\n",
       "1    1360\n",
       "Name: targets, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read DF\n",
    "df_fd = pd.read_csv(\"fraud_detection_bank_dataset.csv\")\n",
    "\n",
    "# Checking out stuff and extracting the class labels\n",
    "df2 = df_fd.copy()\n",
    "df2.info()\n",
    "y_res2 = df2[\"targets\"]\n",
    "\n",
    "# Splitting the dataset into 75/25\n",
    "# Stratified split for equal class proportions in each dataset\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(df2, y_res2, stratify=y_res2, test_size=0.25)\n",
    "\n",
    "# Class proportions of the test data. I hope 3756 vs 1360 this is ok :) \n",
    "display(y_test2.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.74504056e-01, 8.69187310e-04, 3.86161659e-03, ...,\n",
       "        0.00000000e+00, 7.09504685e-02, 0.00000000e+00],\n",
       "       [6.41747288e-01, 0.00000000e+00, 1.74566229e-03, ...,\n",
       "        0.00000000e+00, 6.02409639e-02, 0.00000000e+00],\n",
       "       [6.56259162e-01, 8.69187310e-04, 1.62928481e-02, ...,\n",
       "        0.00000000e+00, 2.67737617e-02, 0.00000000e+00],\n",
       "       ...,\n",
       "       [1.15899541e-01, 0.00000000e+00, 4.49640288e-04, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [1.82204632e-01, 0.00000000e+00, 1.45471858e-03, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [3.95436333e-01, 8.69187310e-04, 1.43620398e-02, ...,\n",
       "        0.00000000e+00, 9.77242303e-02, 0.00000000e+00]])"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MinMax normalization\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit_transform(X_train2)\n",
    "scaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_5k_test():\n",
    "    \n",
    "    # Dropping some columns\n",
    "    X_train_5k = X_train2.drop(['targets', 'Unnamed: 0'], 1)\n",
    "    X_test_5k = X_test2.drop(['targets', 'Unnamed: 0'], 1)\n",
    "\n",
    "    # Train and predict with kNN\n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(X_train_5k, y_train2)\n",
    "    y_pred2 = clf.predict(X_test_5k)\n",
    "    y_pred_proba = clf.predict_proba(X_test_5k)\n",
    "    \n",
    "    # Relevant metrics for the objective\n",
    "    cm = confusion_matrix(y_test2, y_pred2)\n",
    "    accuracy = accuracy_score(y_test2, y_pred2)\n",
    "    auc = roc_auc_score(y_test2, y_pred_proba[:, 1])\n",
    "    \n",
    "    # Print metrics\n",
    "    print(cm)\n",
    "    print(\"Test Accuracy: \", accuracy)    \n",
    "    print(\"Test AUC: \", auc)   \n",
    "    print(classification_report(y_test2, y_pred2, target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3459  298]\n",
      " [ 470  890]]\n",
      "Test Accuracy:  0.8499120578463943\n",
      "Test AUC:  0.8539950915154457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      3757\n",
      "           1       0.75      0.65      0.70      1360\n",
      "\n",
      "    accuracy                           0.85      5117\n",
      "   macro avg       0.81      0.79      0.80      5117\n",
      "weighted avg       0.85      0.85      0.85      5117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# There is a difference in precision between the classes,\n",
    "# whereas the minority class scores lower\n",
    "# Accuracy and AUC of ~.85\n",
    "\n",
    "kNN_5k_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1359\n",
      "0    1359\n",
      "Name: targets, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Copying X_test2 before resampling\n",
    "X_test3 = X_test2.copy()\n",
    "\n",
    "# Resampling the data by selecting 1359 samples of class 0 from X_test3\n",
    "# (corresponding to the amount of test instances of class 1 in X_test2) \n",
    "# For the sample function, replace is by default false (no replacement), \n",
    "# but I choose to demonstrate it here anyways.\n",
    "X_test3 = X_test3.groupby('targets', group_keys=False).apply(lambda x: x.sample(1359, replace=False, random_state=1)).reset_index()\n",
    "y_res3 = X_test3['targets']\n",
    "\n",
    "# Had to drop some columns (indexes) that appeared, and also the classes\n",
    "X_test3.drop(['index', 'Unnamed: 0', 'targets'], axis=1, inplace=True)\n",
    "\n",
    "# Print classes\n",
    "print(y_res3.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_2k_test():\n",
    "    \n",
    "    # Drop some columns\n",
    "    X_train_2k = X_train2.drop(['targets', 'Unnamed: 0'], 1)\n",
    "    X_test_2k = X_test3.copy()\n",
    "    \n",
    "    # Train and predict with kNN\n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(X_train_2k, y_train2)\n",
    "    y_pred3 = clf.predict(X_test_2k)\n",
    "    y_pred_proba = clf.predict_proba(X_test_2k)\n",
    "  \n",
    "    # Relevant metrics for the objective\n",
    "    cm = confusion_matrix(y_res3, y_pred3)\n",
    "    accuracy = accuracy_score(y_res3, y_pred3)\n",
    "    auc = roc_auc_score(y_res3, y_pred_proba[:, 1])\n",
    "\n",
    "    # Print metrics\n",
    "    print(cm)\n",
    "    print(\"Test Accuracy: \", accuracy)    \n",
    "    print(\"Test AUC: \", auc)\n",
    "    print(classification_report(y_res3, y_pred3, target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1258  101]\n",
      " [ 470  889]]\n",
      "Test Accuracy:  0.7899190581309786\n",
      "Test AUC:  0.8531426767615238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82      1359\n",
      "           1       0.90      0.65      0.76      1359\n",
      "\n",
      "    accuracy                           0.79      2718\n",
      "   macro avg       0.81      0.79      0.79      2718\n",
      "weighted avg       0.81      0.79      0.79      2718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can see a an increase in precision for the previous minority class\n",
    "# Interestingly, the previous majority class' precision decreased\n",
    "# Accuracy decreased due to decreased rel. frequency of the majority class\n",
    "# and the AUC is more or less the same since changes in proportion \n",
    "# of the classes does not affect the score.\n",
    "\n",
    "kNN_2k_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
